Title: 2012-04-17 만화 서비스 오픈 후기
Time: 18:46:00

부족한 글이지만, 웹 서비스를 시작하는 다른 이들에게 작으나마 발판이 되기를 기대해며 최근에 오픈한 서비스 후기를 적어본다.

박현우([@lqez](http://twitter.com/lqez)) /
[ez@smartstudy.co.kr](mailto:ez@smartstudy.co.kr)

  

  

**Hardware & IDC**

하드웨어는 애증의 대상이다. 장비를 살 때는 기분이 좋지만, 2-3년 지나 장비가 노후되면 짐이 되는 경우를 많이 봐왔기 때문이다. 따라서,
개발과 서비스가 원할하게 이뤄질 수만 있다면 되도록 클라우드 서비스를 이용하고 싶었다. 미국이나 일본에는 AWS 가 있어 편리하게 인스턴스를
추가해 사용해왔지만, (1) 한국에는 AWS가 아직 들어오지 않았고(계획하고 있는 것으로 안다), (2) 그나마 가까운 Tokyo 인스턴스도
150ms 정도의 레이턴시가 기본이며, 최대 속도도 2-3MiB/sec에 불과하고, (3) 가격적인 면에서도 한국 IDC에 직접 입주하는
것에 비해 결코 싸지 않다. 대안으로 생각한 것이 ucloud인데, 블로그에 계속 적어왔듯 아직은 쓸만한 서비스가 아니라 판단해서
제외했다.클라우드 서비스에서 가져야할 가장 기본적인 요소는 안정성 임에도 불구하고, 예고되지 않은 서비스 점검이나 사용자들의 각종 불만
글들을 미루어 볼 때, 안정화에 대한 역량이 부족한 것으로 보여 선택하지 않았다.

  

남은 방법은 IDC에 직접 입주하는 것이었고, cafe24와 같이 저렴한 서비스부터, NHN Business Platform(이하 NBP)과
같이 상대적으로 고가의 서비스까지 검토하였다. 결국, NBP에 입주했고, 그 과정에는 안면이 있는 분들이 근무한다는 점과, 같이 일했던 다른
분들도 잘 쓰고 있다는 이유도 있었지만, 객관적으로 따져봐도 (1) 상면과 회선 비용이 10% 정도 비싸긴 하지만, 2종류의 메트로 회선을
사용해서 상대적으로 안전 (2) L3 스위치부터 이중화에 대한 기본 지원이 확실 (3) 아직은 사용하지 않지만 L4도 장비 대여가 아닌,
cps 단위로 계약하여 저렴하게 사용 가능 (4) IDC 입주, 설치부터 운용까지 책임지고 담당하게 하는 고객사별 담당자(SIM) 지원
(5) 향후 IaaS, PasS 서비스 로의 확장을 검토하고 있는 점등이 마음에 들었다.

  

이제까지 IDC에 입주시킨 서버는 모두 Dell에서 직접 구입한 서버들이지만, 서버 구입과 배송까지 걸리는 시간이 6-8주 정도로 서비스
확장에 능동적으로 대응하기가 매우 어려운 수준으로, 앞으로 대부분의 서버를 임대해 사용할 예정이다. NBP는 리스에 대해서도 자체 저전력
서버를 임대해주거나, 원하는 경우 외부 업체와 협력하여 최대한 빠른 시간내에 하드웨어 추가를 지원해 준다고 한다. 가격적인 면에서 가장 비싼
것이 사실이나, 일 년에 단 한 번, 단 몇 시간 만이라도 장애가 발생한다면, 금전적으로 수 백, 때에 따라선 수 천만원 이상의 손해가
나오는 것이니, 인프라를 가격대 성능비를 우선시하여 선택하는 것은 바람직하지 않다는 변명을 해본다.

참고 :[http://www.nbp-corp.com/](http://www.nbp-corp.com/)

  

  

  

**Software**

이전에도 여러 오픈소스를 사용해서 서비스를 해왔지만, 이번만큼 완전히 오픈소스 기반 서비스를 한 것은 처음이다. OS Ubuntu
Server11.04 x64 / 데이터베이스 MySQL InnoDB / 통계용 데이터베이스 MongoDB / 백엔드 프레임워크 Django
/ 프론트 프레임워크 jQuery / 파이썬 실행기 uwsgi / 웹 서비스 nginx / 캐시 서버 memcached / 모니터링
cacti / 패키지 라이브러리 npk / 배포 rsync, lftp / 그외 각종 css, js 라이브러리들 모두 오픈소스다.

  

  

Ubuntu Server

RHEL, CentOS를 사용하는 사람이라면 Ubuntu를 서버 OS로 사용하는 사람을 이상하게 생각할지도 모르겠다. 그들의 입장에서는 마치
Windows Server 2008 R2가 아닌, Windows XP를 서버 OS로 사용하겠다는 사람으로 보일테니 말이다. 하지만
Python의 최신 버전을 사용하고자 할 때 CentOS를 고집하는 것은, 일부러 가시밭길을 선택하는 것과 다름이 없다. 보안과 관련된
부분에서 깐깐한 OS임은 알지만, 그런 일에 발목잡히고 싶진 않다. 무엇보다 개발 환경에서 Ubuntu / Debian 계열을 오래
사용해오다 보니, 사소한 디렉토리 설정이나 서비스 구성이 다른 것이 불편하고, 서비스 환경과 개발 환경을 100% 똑같이 맞추고 싶은 욕심이
강해, 서버도 Ubuntu Server를 선택하게 되었다. 추가적으로, 다른 부품에 비해 상대적으로 저렴한 가격대를 유지하고 있는 메모리
활용을 위한 x64 선택은 당연한 것.

참고 :[http://serverfault.com/questions/53954/centos-vs-
ubuntu](http://serverfault.com/questions/53954/centos-vs-ubuntu)

  

  

MySQL

django ORM에 의존하다보니, 데이터베이스는 무엇을 쓰더라도 큰 상관은 없었다. 그저 오래 운영해왔던 MySQL이 있었고, 트랜잭션이
지원되는 InnoDB가 있어서 MySQL을 선택했다. 현재까지는 만족. 단, InnoDB는 MyISAM과 달리 Table row count가
없으니 전체 오브젝트의 수를 세지 않도록 주의하고 있다. Query cache의 크기와 Sort buffer를 조절하여 최적의 성능을 내도록
모니터링하고 있다. 아직까지는 서비스 규모가 작으니 별 부담이 없는 수준. 1초 이상의 slow query를 계속 남기고, 쿼리 최적화를
통해 개선하기 쉽지 않은 일부 쿼리는 MySQL Query cache만 믿지 않고, django단에서 memcached쪽으로 얹어, 쿼리
결과를 반복해서 사용하도록 조정하였다.

참고 :[http://dba.stackexchange.com/questions/4303/optimizing-innodb-default-
settings](http://dba.stackexchange.com/questions/4303/optimizing-innodb-
default-settings)

  

  

MongoDB

요즘 MongoDB를 안 좋게 평가하는 글이 많이 보인다. 모든 도구는 각각 장단점이 있고, 그 용도에 걸맞게 사용하면 괜찮지 않은가? 하고
반문해보지만, map-reduce 성능이 유사 제품에 비해 엄청나게 느리고 ( 예전에는 C++이 아니라 무려 Javascript상에서
구현되어 있었다 ), sharding은 늘 그 안정성에 문제 제기가 되고 있다.

  

기존에는 MySQL의 MyISAM이나 Archive 테이블에 로그를 쌓고 분석했었는데, 이 과정에서 (1) 로그 특성에 따라 별도로 테이블을
만들면 테이블이 너무 많아져 관리가 어려워지고, (2) 하나의 테이블에 뭉뚱그려 넣으면 RDBMS의 장점인 aggregation이 퇴색되는
것이 문제였다. (3) 게다가 서비스하는 앱이 수 백종에, 각 앱의 로그 형태가 수 십개씩 되다 보니, 이를 모두 RDBMS에 적절히 넣기는
어렵게 되었다. 그래서 선택한 것이 JSON을 바로 저장할 수 있고, Shard 기능을 통해 수평적 확장이 쉽다는 MongoDB. 쌓는 과정
자체는 편리하고, 빠르고, 좋았지만 막상 통계/분석하는 시점이 되니 MongoDB의 낮은 퍼포먼스가 문제가 되었다. 단순히 distinct
만 해보려고 해도, 열이 1만개 이상이면 map-reduce 사용을 강요받게 되고, map-reduce를 하자니 너무 느려서 쓸 수가
없었다. 현재 약 4억건 - 750GiB의 데이터가 들어 있어, 메모리 크기보다 작은 데이터 셋을 운용해야 제대로 된 성능이 나오는
MongoDB에서는 통계 분석이 불가능하다.

  

결국, MongoDB는 data warehouse 용도로 변경되어 데이터를 계속해서 쌓기만 하고, MySQL쪽으로 분석하고자하는 데이터를
옮겨와 기존과 같은 방식으로 통계를 내고 있다. 5분 단위로 MongoDB slave node에서 MySQL 쪽으로 데이터를 긁어오고,
처리된 통계 데이터는 다시 JSON으로 가공되어 Google chart를 통해 모니터링 페이지에 표시된다.

  

참고 : Don't use MongoDB /[http://pastebin.com/raw.php?i=FD3xe6Jt](http://news.y
combinator.com/item?id=3202081)

참고 : 개발사 10gen CEO의 해명 글 / [http://news.ycombinator.com/item?id=3202081](http:
//news.ycombinator.com/item?id=3202081)

참고 :[http://stackoverflow.com/questions/3947889/mongodb-terrible-mapreduce-
performance](http://stackoverflow.com/questions/3947889/mongodb-terrible-
mapreduce-performance)

참고 : MongoDB 2.0 Release note 번역 /[http://blog.naver.com/ez_/140138562676](htt
p://blog.naver.com/ez_/140138562676)

참고 : Google Chart
/[https://developers.google.com/chart/](https://developers.google.com/chart/)

  

  

Django

Python으로 웹 개발을 하는 사람이라면 누구나 들어봤을 Django를 사용했다. URL dispatcher / ORM / Template
engine 까지 모두 내장한 풀 스택 웹 프레임워크로, (1) Django 개발자 문서가 잘 되어 있는 점 (2) Django
snippet 이나 stackoverflow에 참고할 만한 외부 리소스가 충분 (3) 한국어로 번역된 서적도 있다는 점에서 선택하게 되었다.

  

Template filter / Context processor / Custom Widget 등을 추가하는 과정이 다소 귀찮은데, 이런
부분은 아마도 다른 경량 프레임워크(flask등)기반으로 작업하는 것이 더 편했을 것 같다. 하지만 이미 개발되어 있는 미들웨어를 손쉽게
도입하는 과정은 매력적이었다. 서비스 오픈 직전에 django-compressor를 추가하여 css, js를 최소화/캐싱하여 내려보내도록
하였고, django cache framework를 통해 데이터베이스 쿼리 결과나 템플릿 렌더링 결과물을 세팅에 따라 개발시에는 dummy
backend로, 테스트 환경과 서비스 환경에서는 memcached backend로 바로 적용해볼 수 있어 좋았다.

참고 :django compressor /[http://django_compressor.readthedocs.org/en/latest/](h
ttp://django_compressor.readthedocs.org/en/latest/)

참고 : django cache backend / [https://docs.djangoproject.com/en/1.3/topics/cach
e/](https://docs.djangoproject.com/en/1.3/topics/cache/)

하지만, django cache framework에도 치명적인 단점이 있는데, cache가 expire된 직후에 들어온 요청들이 동시에
몰리면서 CPU 사용율이 폭주하는 경우가 있다. 서버 단에서 클라이언트에서의 요청 없이 미리미리 expire 되기 전에 생성해서 넣어주는
방식이면 좋겠지만, @cache등을 사용한 per-view 캐시를 사용하면, (1) 캐시가 expire 된다 (2) 동일한 요청이 수 십개
들어온다 (3) 캐시가 없으므로 여러 요청이 오래 걸리는 연산 과정을 동시에 수행한다 (4) 순간적으로 느려진다는 문제가 있다.

참고 :[https://docs.djangoproject.com/en/1.3/topics/cache/#the-per-view-
cache](https://docs.djangoproject.com/en/1.3/topics/cache/#the-per-view-cache)

  

이건 사실 cache framework의 문제나 memcached의 문제는 아니지만, 데코레이터를 써서 편하게 캐시를 활용하고자 하는
사용자에게는 아쉬운 부분이다. 이를 위해 expire되기 n초 전에 미리 캐시를 준비해주는 cache argument를 추가로 지정할 수
있으면 좋겠다. (즉, 동시에 여러 요청이 들어와 느려지지 않도록)더불어, URL로 쪼개지지 않는 ( 예: 세션의 값 ) 경우에는 수작업으로
키를 생성하고 읽기/쓰기를 진행해야 하는 것도 불편하다. @vary_on_headers나 @vary_on_cookie는 있지만
@vary_on_session 이나 @vary_on_function 등이 없기 때문이다. 추후 개발해볼 만한 부분이 되겠다.

참고 :[https://docs.djangoproject.com/en/1.3/topics/cache/#using-vary-
headers](https://docs.djangoproject.com/en/1.3/topics/cache/#using-vary-
headers)

  

  

nginx and uwsgi

이전까지는 python 서비스를 apache2 + mod_python을 써서 진행했는데, static 파일의 전송에서의 성능이나,
python 웹 서비스에는 uwsgi + nginx 의 조합이 메모리 사용량와 동시 처리성 면에서 좋다는 벤치마크를 보고 처음 사용해보았다.

참고 : Benchmark of python web deployment /[http://nichol.as/benchmark-of-
python-web-servers](http://nichol.as/benchmark-of-python-web-servers)

참고 : Mac OS X 에서 django + nginx + uwsgi 환경 구성 /[http://blog.naver.com/ez_/1401
49955374](http://blog.naver.com/ez_/140149955374)

  

ab와 httperf 를 통해 개발 환경에서 테스트해보았는데, apache2 + mod_python과의 직접 비교는 해보지 못했다. 단,
static file의 전달은 확실히 nginx쪽이 빠르고, uwsgi가 메모리를 적게 소모하는 것이 사실이다. 추후 reverse
proxy 구성 등에도 apache reverse proxy 대신 사용해보는 것도 좋겠다.

참고 :[http://httpd.apache.org/docs/2.0/programs/ab.html](http://httpd.apache.or
g/docs/2.0/programs/ab.html)

참고 :[http://www.hpl.hp.com/research/linux/httperf/](http://www.hpl.hp.com/rese
arch/linux/httperf/)

참고 : [http://tumblr.intranation.com/post/766288369/using-nginx-reverse-
proxy](http://tumblr.intranation.com/post/766288369/using-nginx-reverse-proxy)

참고 :[http://stackoverflow.com/questions/900875/is-ab-or-httperf-better-for-
checking-performance-of-a-website](http://stackoverflow.com/questions/900875
/is-ab-or-httperf-better-for-checking-performance-of-a-website)

  

  

memcached

요즘은 안 쓰면 되려 이상한 것이 캐시 프레임워크다. 다양한 캐시 프레임워크가 존재하지만, django에서 기본 지원하는 cache
backend 로는 memcached / file-system / in-memory 등이 있으며, 요즘 한창 유행하는 redis
backend도 github 등에서 쉽게 찾아볼 수 있다.

참고 :[https://github.com/sebleier/django-redis-
cache](https://github.com/sebleier/django-redis-cache)

  

memcached의 단점이라면, redis persistence 처럼 디스크를 통해 값을 저장하는 방법이 없어, 재시작이나 신규 서버 추가
시, 없는 캐시를 채우느라 순간적으로 퍼포먼스가 저하되는 문제가 있다. 하테나 엔지니어가 쓴《서버/인프라를 지탱하는 기술》등에서도
얘기하지만, 이러한 경우에는 서비스에 넣기 전에 디스크 캐시나 캐시 프레임워크의 메모리를 충분히 '달구는' 작업이 필요하다.

참고 :《서버/인프라를 지탱하는 기술》소개
/[http://blog.outsider.ne.kr/711](http://blog.outsider.ne.kr/711)

  

redis와 memcached 의 벤치마크는 다양하게 올라오고 있는데, redis 개발자가 적은 아래 글이 나에겐 신뢰가 간다. 따라서,
신규 서버에서는 AOF 기반의 redis 사용을 검토중이다.

참고 : [http://antirez.com/post/redis-memcached-
benchmark.html](http://antirez.com/post/redis-memcached-benchmark.html)

  

  

npk

직접 만든 ANSI C 기반의 저수준 파일 패키징 라이브러리로, 이번 서비스에서도 만화 이미지 파일을 암호화하여 패키징 하였다. 사실
암호화라는 것이 뚫으라고 만드는 것이라 큰 의미는 없을 수도 있으나, 콘텐츠에 대한 최소한의 예의(?) 차원에서 패키징하였다. iOS쪽은 C
소스를 그대로 내장하여 진행하였고, Android는 JNI를 구성하여 사용하고 있다.

  

npk에서 지원하는 streamable package 형태로 패키지를 구성하여, 만화 콘텐츠를 모두 다운로드 받지 않은 경우에도 미리
보여주도록 하였다.

참고 :[http://code.google.com/p/npk/](http://code.google.com/p/npk/)

참고 : Streamable package sample /[http://code.google.com/p/npk/source/browse/tr
unk/libnpk/tests/libnpk_streamable.cpp](http://code.google.com/p/npk/source/br
owse/trunk/libnpk/tests/libnpk_streamable.cpp)

  

  

jQuery

이제는 javascript 위의 하나의 레이어와 같은 jQuery, 별다른 설명이 필요가 없다. 게다가 이를 중심으로 한 생태계가 거대하기
때문에, jQuery를 사용하지 않는 자바스크립트 플러그인을 골라 사용하기도 어렵다. 물론, 가벼운 구현을 위해 jQuery를 사용하지 않는
라이브러리들도 있지만, 여전히 그 위세가 대단한 라이브러리.

참고 :[http://jquery.com/](http://jquery.com/)

참고 : 최적화 관련 /[http://hungred.com/useful-information/jquery-optimization-tips-
and-tricks/](http://hungred.com/useful-information/jquery-optimization-tips-
and-tricks/)

참고 : 최적화 관련 /[http://www.artzstudio.com/2009/04/jquery-performance-
rules](http://www.artzstudio.com/2009/04/jquery-performance-rules)

  

  

Testing

django가 admin과 더불어 자랑하는 기능 중 하나인 유닛 테스트 모듈을 사용하지 못해 아쉽다. admin 모듈과 더불어 서비스하며
추가 개발하여 개선해야할 부분이라고 생각한다. 서비스가 확대되면 분명 사람이 테스트 하는 범위는 한계가 생기므로, unit testing와
더불어 integration testing까지 겸한 기계적인 테스트를 반드시 추가해야 한다.

참고 :[https://docs.djangoproject.com/en/1.3/topics/testing/](https://docs.djang
oproject.com/en/1.3/topics/testing/)

  

기존에 테스트를 하려면 접속 URL을 변경 후, 다시 애플리케이션을 설치하여 테스트를 하거나, 직접 host file 등을 수정해야 했으나,
이번에는 테스트를 위한 특별한 AP를 구축해 두고, 해당 AP에 접속시 개발 DNS를 사용하도록 구성해, 같은 도메인에 대해 개발 서버로
접속할 수 있게끔 구성하였다.사무실 인원이 적은 관계로, (1) 모든 인원이 무선랜을 사용하고 있었으며 (2) iOS나 Android
기기에서는 DNS 설정 변경이 매우 귀찮고 (3) host file 수정이 어려우므로 이와 같은 방법으로 테스트를 진행하였다.

참고 : 스마트 디바이스를 위한 테스트 환경 구축 /[https://docs.google.com/present/view?id=dfj42qk4
_48xrfrvbfb](https://docs.google.com/present/view?id=dfj42qk4_48xrfrvbfb)

  

  

Deploy

파이썬 프로그램의 배포는 fabric을 쓰는 것이 정답인 것 같지만, 초기 배포 시스템을 만들던 시기에는 이 패키지의 존재를 몰랐기에,
git + rsync + bash shell script로 구성했다. 우선,개발 서버는 리얼 서버와 동일한 플랫폼(OS 및 이 글에서
언급하는 모든 것들)으로 구성하였고,개발 서버의 특정 디렉토리에 테스트해야 할 시스템을 구축하고, 테스트가 완료되면 해당 디렉토리 전체를
deploy 디렉토리로 옮긴다. 이 과정을 git commit 이후에 git pull 로 구현하여 배포 과정에서의 로그 메세지를 수집하고,
롤백 가능하도록 하였다.

참고 : fabric /[http://docs.fabfile.org/en/1.4.1/index.html](http://docs.fabfile
.org/en/1.4.1/index.html)

  

리얼 서버는 dpkg로 설치 가능한 것들은 미리 설치하여 두고, pip는 사용하지 않았다. 얼마 전, 서버 추가 구성시에 pip 사이트가
다운되어 원하는 패키지를 설치할 수 없는 문제를 겪었기 때문에, 개발 환경의 virtualenv를 그대로 리얼 서버로 배포하고 있다.
nginx와 uwsgi도 직접 소스 컴파일한 버전을 사용하기 때문에, 해당 바이너리도 같이 배포한다.

참고 : virtualenv /[http://pypi.python.org/pypi/virtualenv](http://pypi.python.o
rg/pypi/virtualenv)

참고 : virtualenv & virtualenv wrapper 사용기 /[http://blog.naver.com/ez_/140138625
021](http://blog.naver.com/ez_/140138625021)

  

서비스 개발을 한참 진행한 이후에야, django 프로젝트를 많이 경험한 사람들이 제안하는 디렉토리 구조를 알게 되어, 아쉽지만 초기에
막무가내로 구성했던 아래의 구조를 그대로 사용하고 있다. 사용에 문제점은 없지만 아래 링크를 통해 좋은 구조를 선택하는 것이 프로젝트 초기에
선행되어야 한다.아래에 언급한디렉토리 중, data 디렉토리는 sorl-thumbnail 등이 생성하는 썸네일과 django
compressor가 생성하는 캐시 파일도 저장되므로, 동기화를 위해 nfs 로 묶어 특정 서버의 디렉토리만 사용중이다. 성능 개선을 위해
해당 디렉토리를 SSD 드라이브로 옮기는 것을 준비중이다.

참고 : django 프로젝트 구조 제안 /[https://github.com/garethr/django-project-
templates](https://github.com/garethr/django-project-templates)

참고 : sorl thumbnail library /
[http://thumbnail.sorl.net/](http://thumbnail.sorl.net/)

  

> /etc  # nginx, uwsgi 외 기타 설정 파일들

>

> /bin  # nginx, uwsgi 를 직접 빌드한 파일들

>

> /env  # virtualenv - python home

>

> /collected_static # manage.py collectstatic을 통해 흩어져 있는 static 파일을 모은 곳.
nginx로 서빙.

>

> /web  # django home

>

> /api  # 클라이언트 앱과 통신하는 모듈

>

> /app # django app 디렉토리

>

> /some-app # 특정 app

>

> /static # 해당 app에서 사용하는 static 파일들

>

> /templates # 해당 app에서 사용하는 template 파일들

>

> ...

>

> /data # 개발 도구에서 전달된 미리 만들어진, 서버에 배포되야 하는 파일들

>

> /library # django widget, template processor 등 python 라이브러리

>

> /static # 공용 리소스

>

> /js # 직접 개발한 자바 스크립트

>

> /css # 자체 CSS

>

> /lib

>

> /jquery #외부 프론트엔드 라이브러리를 디렉토리 단위로 관리

>

> /lazyload

>

> /swipe

>

> ...

>

> /templates # 공용 템플릿

>

> settings.py # 개발 / 리얼 공용 설정 파일

>

> settings_local.py # 특정 환경에서의 설정 파일, settings.py의 끝 부분에서 로딩

>

> urls.py # 주 url dispatcher

>

> wsgi.py # uwsgi에서 사용

위와 같은 구조를 rsync / lftp로 리얼 서버로 전송한다. lftp는 rsync가 지원되지 않는 환경을 위해 사용하고 있으며, 파일
제외나 dry-run 등의 옵션이 잘 제공되어 rsync와 큰 차이 없이 사용할 수 있는 것이 장점이다. 현재 사용중인 GS네오텍의 CDN
서비스도 FTP만 지원하는 관계로 아래의 옵션으로 dry run / sync를 수행하고 있다.

참고 :[http://www.gsneotek.co.kr/](http://www.gsneotek.co.kr/)

참고 :[http://rsync.samba.org/](http://rsync.samba.org/)

참고 : [http://lftp.yar.ru/](http://lftp.yar.ru/)

  

> **rsync : dry run**

>

> $ rsync -rvn --delete --copy-links --exclude-from=excludes_list_file <SRC>
<DST>

>

> **rsync : sync**

>

> $rsync -av --progress --inplace --delete --copy-links --exclude-
from=excludes_list_file<SRC> <DST>

>

> **lftp : dry run**

>

> $lftp <HOST> -u <USERNAME>,<PASSWORD> -e "mirror -c -e -L -R -p -v --dry-run
`sed \'s/^/-x /\' /excludes_list_file | sed \'s/*//g\' | tr \'\n\' \' \'`
\'<SRC>\' \'<DST>\'; bye"

>

> **lftp : sync**

>

> $lftp <HOST> -u <USERNAME>,<PASSWORD> -e "mirror -c -e -L -R -p -v `sed
\'s/^/-x /\' /excludes_list_file | sed \'s/*//g\' | tr \'\n\' \' \'` \'<SRC>\'
\'<DST>\'; bye"

가능하면 IDC 내 배포 서버를 두고 테스트 후, 배포 서버에서 리얼 서버로 배포하는 방식을 쓰고 싶지만, 여유가 없는 관계로 개발 / 배포
서버를 하나로 유지하고 있다. 마지막으로, 여러 서버의 설정 값을 변경하거나 같은 작업을 반복하는 경우에 tmux의 synchronize-
panes 기능으로 간간히 재미를 보았다.

참고 :[http://amjith.posterous.com/synchronize-panes-in-
tmux](http://amjith.posterous.com/synchronize-panes-in-tmux)

  

배포한 이후 서버 인스턴스 재시작도 원격에서 이뤄지며, 위 배포 시스템으로 이미 서버로 배포된 shell script를 원격지에서 ssh
piping으로 호출하여 각 서버를 재시작한다. 각각의 서버에 ssh piping을 하는 일도 shell script로 작성하였다. 이
작업을 위해 (1) 공통으로 사용할 원격지 제어용 아이디를 개발 서버에 생성 (2) 해당 아이디의 ssh pub key를 각 서버에 전달
(3) 해당 아이디를 sudoer에 NOPASSWD 사용자로 등록하여 사용하고 있다.

참고 :[http://linux.icydog.net/ssh/piping.php](http://linux.icydog.net/ssh/pipin
g.php)

참고 :[http://ubuntu-tutorials.com/2007/02/05/unattended-ssh-login-public-key-
ssh-authorization-ssh-automatic-login/](http://ubuntu-tutorials.com/2007/02/05
/unattended-ssh-login-public-key-ssh-authorization-ssh-automatic-login/)

  

  

Monitoring

안 써봤던 munin / nagios 등을 써보고 싶었으나, 시간 관계상 결국 cacti를 다시 사용하게 되었다. 이번에는 기본 SNMP뿐
아니라 Percona에서 제공하는 ssh-based monitoring plugin을 통해 MongoDB / MySQL / nginx /
Apache / memcached 등을 추가로 모니터링하고, Threshold 플러그인을 추가해 특정 이벤트 발생시 메일로 바로 알람을
보내는 정도의 기능을 추가하는데 그쳤다. 최소한의 셋업이지만, 실제 서비스를 모니터링하는데 부족함은 없는 상태.

참고 :[http://www.cacti.net/](http://www.cacti.net/)

참고 :[http://www.percona.com/software/percona-monitoring-
plugins/](http://www.percona.com/software/percona-monitoring-plugins/)

참고 :[http://docs.cacti.net/plugin:thold](http://docs.cacti.net/plugin:thold)

  

  

Libraries

덩치 큰 프레임워크나 견고한 라이브러리의 도움도 많이 받았지만, 작고 빛나는 보석과 같은 아래 라이브러리들의 도움이 없었으면, 웹의 완성도를
높일 수 없었을 것이다.

  

apprise

웹뷰에서 alert / confirm 등을 사용하면 팝업 메세지에 웹 페이지 주소가 노출되는 단점 아닌 단점이 있는데, 이것이 싫다면 div
를 통한 팝업 구현이 필요하다. 그리고 iOS 4.X나 안드로이드 웹뷰에서 position: fixed를 사용할 수 없어, 고정된 위치에
팝업을 띄우는 것이 귀찮은 편인데, 이를 대신해주는 라이브러리. 반복적인 class selector 호출 등의 최적화 되지 않은 jQuery
사용이 있어, 그러한 부분을 개선하여 사용하였다.

참고 :[http://thrivingkings.com/apprise/](http://thrivingkings.com/apprise/)

  

cross-slide

Ken-burns 스타일의 사진 슬라이드 효과를 내기 위해 사용

참고 :[http://tobia.github.com/CrossSlide/](http://tobia.github.com/CrossSlide/)

참고 : 사용기 /[http://blog.naver.com/ez_/140156789842](http://blog.naver.com/ez_/1
40156789842)

  

iscroll

iOS / Android 등에서 pinch to zoom / pull to refresh / overflow:scroll 를 구현하기 위한
라이브러리. 많이 사용하진 않았지만, 웹에서 사용성을 높이기 위해서는 한 번 쯤 살펴볼만 하다.

참고 :[http://cubiq.org/iscroll-4](http://cubiq.org/iscroll-4)

  

jstorage

Local storage를 사용하기 위한 라이브러리. 서버와 통신할 필요가 없는 값들을 읽고 쓰기 위해 사용하였다. 간단하고 사용하기
편리하다.

참고 :[http://en.wikipedia.org/wiki/Web_storage](http://en.wikipedia.org/wiki/We
b_storage)

참고 :[http://www.jstorage.info/](http://www.jstorage.info/)

  

lazyload

화면에 보이지 않는 부분의 이미지들은 굳이 미리 서버에서 가져올 필요가 없다. lazyload를 통해 트래픽을 줄이고, 페이지 로드 시간을
단축할 수 있다. 모든 웹 페이지에서 가지면 좋은 기능이지만, 모바일 웹에서는 반드시 가져야 할 요소.

참고 :[http://www.appelsiini.net/projects/lazyload](http://www.appelsiini.net/pr
ojects/lazyload)

참고 : 사용기 /[http://blog.naver.com/ez_/140156676013](http://blog.naver.com/ez_/1
40156676013)

  

spin.js

ajax 요청등을 보내고 기다릴 때, 흔히 볼 수 있는 activity indicator를 animated gif 등으로 처리하는 것이
일반적이었다면, spin.js 를 통해 이미지 없이 멋진 spin image를 만들어낼 수 있다. 단, 안드로이드 일부기기에서 지원하지 않는
문제가 있어 현재는 울며 겨자먹기로 animated gif 를 사용중.

참고 :[http://fgnass.github.com/spin.js/](http://fgnass.github.com/spin.js/)

  

swipe

모바일 기기의 swipe 기능을 이 라이브러리를 통해 웹에서 완벽히 재현할 수 있다. lazyload와 함께 사용해, 다른 페이지에 있는
이미지들을 나중에 불러오도록 구성하면 최적. 단, 기본적으로 제공하는 callback은 webkit의 transitionEnd 시점에
발생하는 것이라, swipe를 시작하는 시점에 callback을 받으려면 몇 줄의 코드를 추가해야 한다.

참고 :[http://swipejs.com/](http://swipejs.com/)

참고 : 수정된 swipe.js
/[https://gist.github.com/2404749](https://gist.github.com/2404749)

  

zflow

웹에서 coverflow 효과를 줄 때 사용한 라이브러리. iOS쪽은 iPhone 3Gs에서도 충분히 부드럽고 빠르게 작동하지만,
Android에서는 OS와 기기에 따라 제대로 지원되지 않는 경우가 많다. 특히 rotateY 등의 transform 적용시, 잘못된 축으로
회전된 결과가 나오므로 Android기기일 경우는 몇 가지 fallback을 추가로 작업해야 사용가능한 상태가 된다. 안드로이드에서는 크기나
회전은 제외하고, opacity를 조정하는 정도로만 사용하고 있다. 이 점만 유의하면 충분히 쓸만한 라이브러리인 듯.

참고 : [http://code.google.com/p/css-vfx/](http://code.google.com/p/css-vfx/)

  

  

  

  

Post-mortem

  

약 4개월간 같이 서비스를 준비한 개발자들과 서비스를 오픈한 후, 포스트 모템 자리를 가졌을 때 주된 주제는 "다시 한 번 유사 서비스를
개발한다면, 지금과 같은 웹/앱 하이브리드 형태로 개발할 것인가?" 였다.

  

하이브리드 앱의 단점은 (1) 웹 / 앱에서의 디자인, 사용자 경험에서의 일관성 유지의 어려움 (2) 웹의 상대적으로 부족한 반응성 (3)
개발자에게 요구되는 넓은 기술 범위 등이 될 것이다. 반대로 장점을 꼽아보면 (1) 서비스 코드는 시간의 흐름에 따라 잦은 변경과 빠른
대응이 요구되는데, 전체를 앱으로 구성한 경우 iOS와 같이 플랫폼 홀더에서 심사하는 구조에서는 그런 것이 불가능한데 비해, 웹으로 구성한
덕에 불편함을 제거할 수 있음 (2) 1-2개 플랫폼이면 몰라도, 추가로 Bada나 Windows Phone 등으로 플랫폼을 늘리는 경우,
별도의 서비스 코드 추가 없이, 높은 반응성과 속도가 요구되는 부분만 네이티브로 구현하면 된다는 장점이 있다.

  

추가적으로, 인원 구성에 따라 웹 개발 경험이 충분하고 네이티브 앱 개발 경험이 부족하거나 인원이 부족한 경우, 일을 나눠 할 수 있는 것도
장점이다. 이번 개발 조직의 경우, 1년 정도의 iOS / Android 개발 경험자와 3년 정도의 웹 개발 경험자로 구성되어 있어
하이브리드 앱 개발에 비교적 용이한 인원 구성이었던 것으로 생각된다. 속도가 최우선이 아닌, 상점이나 커뮤니티 등 서비스 코드가 대부분을
차지하는 곳에서는 라이브한 대응이 가능한 웹으로 구성한 것이 전체 개발 시간을 단축할 수 있었던 요인인 것 같다. 대신 웹으로 구성된 부분의
반응성이 네이티브로 구현된 것 만큼 빠릿하지 않다는 것이 단점인데, 버튼을 눌렀을 때의 리액션이나 UI에서의 표현으로 일부 극복 가능할
것으로 보인다.

  

따라서, 위에서 했던 질문에 답을 하자면, '유사 서비스에 대해서는 다음에도 같은 방법으로 개발할 것이다'.

  

  

  

Thanks to

  

iOS / Android / Django / 인하우스 도구 등 모든 개발을 담당하고 책임지신 박준철님
([@joongom](http://twitter.com/joongom))

iOS / Django 개발을 맡은 손동우님 ([@neoevoke](http://twitter.com/neoevoke))

Android 개발을 담당한 하재훈님 ([@barikang](http://twitter.com/barikang))

본인의 일이 아님에도 디버깅와 꼼꼼한 테스팅을 도와주신
임종휘님([@endorand81](http://twitter.com/endorand81))

대표이사지만, 야밤 코딩을 통해 통계 분석 + 멋진 차트를 만든
김민석님([@_tinysky](http://twitter.com/_tinysky))

  

웹 /앱의 모든 디자인 작업을 해주신 박지은님

앱 / 서비스 기획 뿐만 아니라, 만화 콘텐츠 및 작가 섭외까지의 모든 일을 챙겨주신 윤성국님

일의 물꼬를 터주시는 이승규님

  

모두 수고하셨습니다!

더불어, 부족한 이 글을 읽어주신 모든 분들께도 감사드립니다.

  

